{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7310d5ba",
   "metadata": {},
   "source": [
    "# Autoencoder Inference Notebook\n",
    "\n",
    "This notebook loads the trained autoencoder, applies it to test data, visualizes reconstructions, and prepares submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "info =\"\"\"\n",
    "\n",
    "Author: Annam.ai IIT Ropar\n",
    "Team Name: SoilClassifiers\n",
    "Team Members: Caleb Chandrasekar, Sarvesh Chandran, Swaraj Bhattacharjee, Karan Singh, Saatvik Tyagi\n",
    "Leaderboard Rank: 103\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb4b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ✅ Environment\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ✅ Configuration\n",
    "IMG_SIZE   = 224\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# ✅ Custom Dataset\n",
    "class SoilDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.folder      = folder\n",
    "        self.image_files = [f for f in os.listdir(folder)\n",
    "                            if f.lower().endswith(('.png','jpg','jpeg'))]\n",
    "        self.transform   = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.folder, img_name)\n",
    "        img      = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, img_name\n",
    "\n",
    "# ✅ Transforms (same as training)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ✅ Autoencoder (must match training.py)\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3,  32, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(64,128, 3, stride=2, padding=1), nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64,  32, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32,   3, 3, stride=2, padding=1, output_padding=1), nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# ✅ Load trained model & threshold\n",
    "model     = Autoencoder().to(device)\n",
    "model.load_state_dict(torch.load(\"autoencoder.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "threshold = float(np.load(\"threshold.npy\"))\n",
    "print(f\"Loaded threshold: {threshold:.6f}\")\n",
    "\n",
    "# ✅ Prepare test loader\n",
    "test_ds = SoilDataset(\n",
    "    \"/kaggle/input/soil-classification-part-2/soil_competition-2025/test\",\n",
    "    transform=test_transforms\n",
    ")\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ✅ Inference loop\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for imgs, ids in test_loader:\n",
    "        imgs  = imgs.to(device)\n",
    "        recon = model(imgs)\n",
    "        loss  = nn.MSELoss()(recon, imgs).item()\n",
    "        label = 1 if loss < threshold else 0\n",
    "        results.append((ids[0], label))\n",
    "\n",
    "# ✅ Visualization helper\n",
    "def show_reconstruction(orig, recon):\n",
    "    orig = orig.cpu().squeeze().permute(1,2,0).numpy()\n",
    "    recon = recon.cpu().squeeze().permute(1,2,0).numpy()\n",
    "    fig, axes = plt.subplots(1,2, figsize=(6,3))\n",
    "    axes[0].imshow((orig * 0.229 + 0.485).clip(0,1))\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[1].imshow((recon * 0.229 + 0.485).clip(0,1))\n",
    "    axes[1].set_title(\"Reconstruction\")\n",
    "    plt.show()\n",
    "\n",
    "# Show first 5 reconstructions\n",
    "with torch.no_grad():\n",
    "    for i, (imgs, _) in enumerate(test_loader):\n",
    "        if i >= 5: break\n",
    "        recon = model(imgs.to(device))\n",
    "        show_reconstruction(imgs[0], recon[0])\n",
    "\n",
    "# ✅ Save submission\n",
    "submission = pd.DataFrame(results, columns=[\"image_id\",\"label\"])\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ submission.csv generated\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
